{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Marketplace Product Usage Demonstration - 7Park Data chat and informal text NER"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7Park Data** chat and informal text NER allows you to improve compliance and wrangle more value out of your Slack, Bloomberg, and other chat data. by identifying and extracting companies/organ.\n",
    "\n",
    "Our chat classifier (NER) identifies companies, stock tickers and governmental and non-government institutions.\n",
    "\n",
    "The solution has been optimized on millions of Slack messages and achieves an F1 score of 88% on our data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample notebook requires subscription to the following pre-trained machine learning model packages from AWS Marketplace:\n",
    "\n",
    "**[Chat and informal text NER](https://aws.amazon.com/marketplace/pp/prodview-64zsbbhzwijeo)**\n",
    "    \n",
    "If your AWS account has not been subscribed to these listings, here is the process you can follow for each of the above mentioned listings:\n",
    "\n",
    "1. Open the listing from AWS Marketplace\n",
    "1. Read the **Highlights** section and then **product overview** section of the listing.\n",
    "1. View **usage information** and then **additional resources.**\n",
    "1. Note the supported instance types.\n",
    "1. Next, click on **Continue to subscribe.**\n",
    "1. Review **End user license agreement, support terms**, as well as **pricing information.**\n",
    "1. **\"Accept Offer\"** button needs to be clicked if your organization agrees with EULA, pricing information as well as support terms.\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "If **Continue to configuration** button is active, it means your account already has a subscription to this listing.\n",
    "Once you click on **Continue to configuration** button and then choose region, you will see that a Product Arn will appear. This is the model package ARN that you need to specify while creating a deployable model. However, for this notebook, the algorithm ARN has been specified in **src/model_package_arns.py** file and you do not need to specify the same explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set up environment and view a sample image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we will import necessary libraries and define variables such as an S3 bucket, an IAM role, and sagemaker session to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pprint import pprint\n",
    "import sagemaker as sage\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker import ModelPackage\n",
    "\n",
    "from src.model_package_arns import ModelPackageArnProvider\n",
    "\n",
    "role = get_execution_role()\n",
    "\n",
    "sagemaker_session = sage.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Live Inference Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Deploy the model for performing real-time inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------!"
     ]
    }
   ],
   "source": [
    "# Get the model_package_arn\n",
    "modelpackage_arn = ModelPackageArnProvider.get_model_package_arn(sagemaker_session.boto_region_name)\n",
    "\n",
    "# Define predictor wrapper class\n",
    "def ner_detection_predict_wrapper(endpoint, session):\n",
    "    return sage.RealTimePredictor(endpoint, session, content_type='application/json')\n",
    "\n",
    "# Create a deployable model package\n",
    "ner_model = ModelPackage(role=role,\n",
    "                         model_package_arn=modelpackage_arn,\n",
    "                         sagemaker_session=sagemaker_session,\n",
    "                         predictor_cls=ner_detection_predict_wrapper)\n",
    "\n",
    "# Deploy the model\n",
    "ner_predictor = ner_model.deploy(initial_instance_count=1, \n",
    "                                 instance_type='ml.m5.xlarge',\n",
    "                                 endpoint_name='chat-ner-endpoint')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Perform a prediction on Amazon Sagemaker Endpoint created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'ner': [{'end_pos': 29,\n",
      "          'key': 'netflix',\n",
      "          'start_pos': 22,\n",
      "          'type': 'NE_TICKER_COMPANY'}]}\n"
     ]
    }
   ],
   "source": [
    "sample = {'instance': 'Just checked, and the netflix data looks pretty postive'}\n",
    "\n",
    "# Perform a prediction\n",
    "ner_result = ner_predictor.predict(json.dumps(sample)).decode('utf-8')\n",
    "\n",
    "# View the prediction\n",
    "pprint(json.loads(ner_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Batch Transform Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's use the model built to run a batch inference job and verify it works. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model supports data in [jsonlines](http://jsonlines.org/) format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": 0, \"instance\": \"Just checked, and the nflx data looks pretty postive\"}\n",
      "{\"id\": 1, \"instance\": \"we should definitely boost Apple weight\"}\n",
      "{\"id\": 2, \"instance\": \"Uber just published its lastest revenue number\"}\n",
      "{\"id\": 3, \"instance\": \"The report of tsla will be released today\"}\n",
      "{\"id\": 4, \"instance\": \"atvi got trapped and people just traded it\"}\n"
     ]
    }
   ],
   "source": [
    "# review input file\n",
    "SAMPLE_FILE = 'data/samples.jl'\n",
    "\n",
    "with open(SAMPLE_FILE) as f:\n",
    "    print(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Update the input file to S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_input = sagemaker_session.upload_data(\n",
    "    SAMPLE_FILE, \n",
    "    key_prefix='chat_ner/' + SAMPLE_FILE)\n",
    "print(\"Transform input uploaded to \" + transform_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Run a new transform job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import uuid\n",
    "\n",
    "transformer = ner_model.transformer(1, 'ml.m5.xlarge', \n",
    "                                    accept=\"application/jsonlines\",\n",
    "                                    assemble_with='Line')\n",
    "transformer.transform(\n",
    "    transform_input, \n",
    "    content_type='application/jsonlines',\n",
    "    join_source= \"Input\",\n",
    "    split_type='Line'\n",
    ")\n",
    "transformer.wait()\n",
    "\n",
    "print(\"Batch Transform output saved to \" + transformer.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Inspect the Batch Transform Output in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"SageMakerOutput\":{\"ner\":[{\"end_pos\":26,\"key\":\"nflx\",\"start_pos\":22,\"type\":\"NE_TICKER_COMPANY\"}]},\"id\":0,\"instance\":\"Just checked, and the nflx data looks pretty postive\"}\n",
      "{\"SageMakerOutput\":{\"ner\":[{\"end_pos\":32,\"key\":\"Apple\",\"start_pos\":27,\"type\":\"NE_TICKER_COMPANY\"}]},\"id\":1,\"instance\":\"we should definitely boost Apple weight\"}\n",
      "{\"SageMakerOutput\":{\"ner\":[{\"end_pos\":4,\"key\":\"Uber\",\"start_pos\":0,\"type\":\"NE_TICKER_COMPANY\"}]},\"id\":2,\"instance\":\"Uber just published its lastest revenue number\"}\n",
      "{\"SageMakerOutput\":{\"ner\":[{\"end_pos\":18,\"key\":\"tsla\",\"start_pos\":14,\"type\":\"NE_TICKER_COMPANY\"}]},\"id\":3,\"instance\":\"The report of tsla will be released today\"}\n",
      "{\"SageMakerOutput\":{\"ner\":[{\"end_pos\":4,\"key\":\"atvi\",\"start_pos\":0,\"type\":\"NE_TICKER_COMPANY\"}]},\"id\":4,\"instance\":\"atvi got trapped and people just traded it\"}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "\n",
    "parsed_url = urlparse(transformer.output_path)\n",
    "bucket_name = parsed_url.netloc\n",
    "file_key = '{}/{}.out'.format(parsed_url.path[1:], \"samples.jl\")\n",
    "\n",
    "s3_client = sagemaker_session.boto_session.client('s3')\n",
    "\n",
    "response = s3_client.get_object(Bucket = sagemaker_session.default_bucket(), Key = file_key)\n",
    "response_bytes = response['Body'].read().decode('utf-8')\n",
    "\n",
    "print(response_bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ner_predictor.delete_endpoint()\n",
    "ner_predictor.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "  \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if the AWS Marketplace subscription was created just for an experiment and you would like to unsubscribe, here are the steps that can be followed. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model.\n",
    "\n",
    "**Steps to unsubscribe from the product on AWS Marketplace:**\n",
    "\n",
    "Navigate to Machine Learning tab on Your [Software subscriptions page](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=lbr_tab_ml).\n",
    "Locate the listing that you would need to cancel, and click Cancel Subscription."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
