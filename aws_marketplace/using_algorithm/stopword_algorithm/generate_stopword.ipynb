{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Marketplace Product Usage Demonstration - 7Park Data Stopword Algorithm\n",
    "\n",
    "## Introduction\n",
    "\n",
    "The performance of many NLP algorithms is greatly improved if one removes “stopwords” first. These are words that are frequent in the dataset, but don’t help to discriminate between documents. Information Retrieval in particular, can be quite sensitive to stopwords. Note that not all frequent words are low-information.\n",
    " \n",
    "Most NLP applications that remove stopwords do so using a list of classical words that have been collected over the years. While this suffices for some applications, it can fall short for many domains, which should have their own list of “low-information” words. For example, does the word “natural” help in distinguishing between sentences in Darwin’s The Origin of Species (included in the package)? Given that the book is about the natural world, probably not. However, classical stopword lists will not contain “natural”. This program picks out “natural” as a stopword, along with “life”, “nature”, “different”, etc.\n",
    " \n",
    "It does not however, pick out “selection”; reading through the text, it is apparent that Darwin’s use of “selection” is not as low-information as his use of “natural”. For example, he speaks of “accumulative selection”, “the closest selection”, and so on. So “natural” is picked out as a stopword, while “selection” is not, even though “selection” is more frequent than “natural”.\n",
    " \n",
    "The algorithm is based on a 2005 paper by Lo et al, but has several propriety improvements (e.g. it’s deterministic unlike theirs, which relies on sampling; and you only need to set one parameter). Darwin’s book courtesy of Project Gutenberg."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-requisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This sample notebook requires subscription to the following pre-trained machine learning model packages from AWS Marketplace:\n",
    "\n",
    "**[Stopword Algorithm](https://aws.amazon.com/marketplace/pp/prodview-64zsbbhzwijeo)**\n",
    "    \n",
    "If your AWS account has not been subscribed to these listings, here is the process you can follow for each of the above mentioned listings:\n",
    "\n",
    "1. Open the listing from AWS Marketplace\n",
    "1. Read the **Highlights** section and then **product overview** section of the listing.\n",
    "1. View **usage information** and then **additional resources.**\n",
    "1. Note the supported instance types.\n",
    "1. Next, click on **Continue to subscribe.**\n",
    "1. Review **End user license agreement, support terms**, as well as **pricing information.**\n",
    "1. **\"Accept Offer\"** button needs to be clicked if your organization agrees with EULA, pricing information as well as support terms.\n",
    "\n",
    "**Notes:**\n",
    "\n",
    "If **Continue to configuration** button is active, it means your account already has a subscription to this listing.\n",
    "Once you click on **Continue to configuration** button and then choose region, you will see that a Product Arn will appear. This is the model package ARN that you need to specify while creating a deployable model. However, for this notebook, the algorithm ARN has been specified in **src/algorithm_arns.py** file and you do not need to specify the same explicitly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stopword Algorithm Usage with SageMaker Estimator\n",
    "Firstly, you need to import SageMaker package, get execution role and create session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "\n",
    "role = sage.get_execution_role()\n",
    "sess = sagemaker.Session()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, you can specify parameters of Decision Forest.\n",
    "#### Hyperparameters\n",
    "<table style=\"border: 1px solid black;\">\n",
    "    <tr>\n",
    "        <td><strong>Parameter name</strong></td>\n",
    "        <td><strong>Type</strong></td>\n",
    "        <td><strong>Default value</strong></td>\n",
    "        <td><strong>Range</strong></td>\n",
    "        <td><strong>Description</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>number_of_hits</td>\n",
    "        <td>int</td>\n",
    "        <td>100</td>\n",
    "        <td>1-100</td>\n",
    "        <td>The total number of output stopwords</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>strategy</td>\n",
    "        <td>Categorical</td>\n",
    "        <td>\"medium\"</td>\n",
    "        <td>'conservative' or 'medium' or 'aggressive'</td>\n",
    "        <td>The strategy of calculate the stopwords</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>blacklist</td>\n",
    "        <td>FreeText</td>\n",
    "        <td></td>\n",
    "        <td></td>\n",
    "        <td>A list of string that will not be the stopword. Separate by ';'. Example: 'inc;co;llc'</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "Example of hyperparameters dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_params = {\n",
    "  \"number_of_hits\": 50,\n",
    "  \"strategy\": \"medium\",\n",
    "  \"blacklist\": \"what;it;my\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, you need to create SageMaker Estimator instance with following parameters:\n",
    "<table style=\"border: 1px solid black;\">\n",
    "    <tr>\n",
    "        <td><strong>Parameter name</strong></td>\n",
    "        <td><strong>Description</strong></td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>algorithm_arn</td>\n",
    "        <td>Algorithm arn used for training</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>role</td>\n",
    "        <td>An AWS IAM role. The SageMaker training jobs and APIs that create SageMaker endpoints use this role to access training data and models</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>base_job_name</td>\n",
    "        <td>Prefix for training job name when the fit() method launches</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>train_instance_count</td>\n",
    "        <td>Number of Amazon EC2 instances to use for training. Should be 1, because it is not distributed version of algorithm</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>train_instance_type</td>\n",
    "        <td>Type of EC2 instance to use for training. See available types on Amazon Marketplace page of algorithm</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>input_mode</td>\n",
    "        <td>The input mode that the algorithm supports. May be \"File\" or \"Pipe\"</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>output_path</td>\n",
    "        <td>S3 location for saving the trainig result (model artifacts and output files)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>sagemaker_session</td>\n",
    "        <td>Session object which manages interactions with Amazon SageMaker APIs and any other AWS services needed</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>hyperparameters</td>\n",
    "        <td>Dictionary containing the hyperparameters to initialize this estimator with</td>\n",
    "    </tr>\n",
    "</table>\n",
    "Full SageMaker Estimator documentation: https://sagemaker.readthedocs.io/en/stable/estimators.html\n",
    "\n",
    "Full SageMaker Algorithm Estimator documentation: https://sagemaker.readthedocs.io/en/stable/algorithm.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.algorithm_arns import AlgorithmArnProvider\n",
    "\n",
    "\n",
    "stopword_arn = AlgorithmArnProvider.get_algorithm_arn(sess.boto_region_name) # Get the algorithm_arn\n",
    "\n",
    "stopword_algorithm = sagemaker.algorithm.AlgorithmEstimator(\n",
    "    algorithm_arn=stopword_arn,\n",
    "    role=role,\n",
    "    base_job_name=\"stopword-algorithm\",\n",
    "    train_instance_count=1,\n",
    "    train_instance_type='ml.m5.xlarge',\n",
    "    input_mode=\"File\",\n",
    "    output_path=\"s3://<bucket-name>/<output-path>\",\n",
    "    sagemaker_session=sess,\n",
    "    hyperparameters=stopword_params\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training stage\n",
    "On training stage, Stopword algorithm consume input data from S3 location.\n",
    "This container supports only .tsv (\"tab-separated values\") files with one column data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopword_algorithm.fit({\"train\": \"s3://<bucket-name>/<training-data-path>\"}) # Example of training data in data/train_data_example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inspect the stopword result\n",
    "After training, you will get a model file which contain the stopword list result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the result model\n",
    "! aws s3 cp s3://<bucket-name>/<output-path>/model.tar.gz ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stopword</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>different</td>\n",
       "      <td>0.009377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>life</td>\n",
       "      <td>0.011430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>between</td>\n",
       "      <td>0.012078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>natural</td>\n",
       "      <td>0.012219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>plants</td>\n",
       "      <td>0.012760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>its</td>\n",
       "      <td>0.017336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>most</td>\n",
       "      <td>0.017826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>may</td>\n",
       "      <td>0.025719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>will</td>\n",
       "      <td>0.025883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>each</td>\n",
       "      <td>0.026450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>any</td>\n",
       "      <td>0.029020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>can</td>\n",
       "      <td>0.029060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>all</td>\n",
       "      <td>0.030535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     stopword     score\n",
       "0   different  0.009377\n",
       "1        life  0.011430\n",
       "2     between  0.012078\n",
       "3     natural  0.012219\n",
       "4      plants  0.012760\n",
       "5         its  0.017336\n",
       "6        most  0.017826\n",
       "7         may  0.025719\n",
       "8        will  0.025883\n",
       "9        each  0.026450\n",
       "10        any  0.029020\n",
       "11        can  0.029060\n",
       "12        all  0.030535"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tarfile\n",
    "\n",
    "with tarfile.open(\"model.tar.gz\", \"r:*\") as tar:\n",
    "    stopword_path = tar.getnames()[0]\n",
    "    stopword_df = pd.read_csv(tar.extractfile(stopword_path), names=['stopword', 'score'], sep=\"\\t\")\n",
    "\n",
    "stopword_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Real-time cleaning\n",
    "Firstly, you need to deploy SageMaker endpoint that consumes data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...........\n",
      "---------!"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "predictor = stopword_algorithm.deploy(\n",
    "    initial_instance_count=1, \n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    serializer = json.dumps,\n",
    "    content_type = \"application/jsonlines\",\n",
    "    accept = \"application/jsonlines\",\n",
    "    deserializer = sagemaker.predictor.json_deserializer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Secondly, you should pass a dictionary with 'data' as key to endpoint and get predictions.\n",
    "\n",
    "In this example we are passing a sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': {'data': 'life is beautiful'}, 'stopwords': ['life']}\n"
     ]
    }
   ],
   "source": [
    "predict_data = {'data': \"life is beautiful\"}\n",
    "predict_result = predictor.predict(\n",
    "    predict_data,\n",
    "    {'ContentType': 'application/jsonlines', 'Accept': 'application/jsonlines'}\n",
    ")\n",
    "\n",
    "print(predict_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Don't forget to delete endpoint if you don't need it anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.delete_endpoint(predictor.endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Batch transform job\n",
    "If you don't need real-time prediction, you can use transform job. It uses saved model, compute predictions one time and saves it in specified or auto-generated output path.\n",
    "\n",
    "More about transform jobs: https://docs.aws.amazon.com/sagemaker/latest/dg/how-it-works-batch.html\n",
    "\n",
    "Transformer API: https://sagemaker.readthedocs.io/en/latest/transformer.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer = stopword_algorithm.transformer(\n",
    "    instance_count=1, \n",
    "    instance_type='ml.m5.xlarge', \n",
    "    accept='application/jsonlines',\n",
    "    output_path='s3://<bucket-name>/<output-path>'\n",
    ")\n",
    "transformer.transform(\n",
    "    data=\"s3://<bucket-name>/<input-data-path>/<input-file-name>\", # Example of transform data in data/transform_data_example\n",
    "    content_type='application/jsonlines',\n",
    "    job_name=\"stopword-transformer\"\n",
    ")\n",
    "transformer.wait()\n",
    "print(transformer.output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictor.delete_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, if the AWS Marketplace subscription was created just for an experiment and you would like to unsubscribe, here are the steps that can be followed. Before you cancel the subscription, ensure that you do not have any [deployable model](https://console.aws.amazon.com/sagemaker/home#/models) created from the model package or using the algorithm. Note - You can find this information by looking at the container name associated with the model.\n",
    "\n",
    "**Steps to unsubscribe from the product on AWS Marketplace:**\n",
    "\n",
    "Navigate to Machine Learning tab on Your [Software subscriptions page](https://aws.amazon.com/marketplace/ai/library?productType=ml&ref_=lbr_tab_ml).\n",
    "Locate the listing that you would need to cancel, and click Cancel Subscription."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
